{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Topic modeling is a popular text analysis tool. The ultimate goal of topic modeling is to find various topics that are present in your corpus. Each document in the corpus will be made up of at least one topic, if not multiple topics.\n",
    "\n",
    "In this notebook, we will be covering the steps on how to do Latent Dirichlet Allocation (LDA), which is one of many topic modeling techniques. It was specifically designed for text data.\n",
    "\n",
    "To use a topic modeling technique, you need to provide (1) a document-term matrix and (2) the number of topics you would like the algorithm to pick up.\n",
    "\n",
    "Once the topic modeling technique is applied, your job as a person is to interpret the results and see if the mix of words in each topic make sense. If they don't make sense, you can try changing up the number of topics, the terms in the document-term matrix, model parameters, or even try a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #1 (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaahm</th>\n",
       "      <th>aah</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdul</th>\n",
       "      <th>abg</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abortions</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroes</th>\n",
       "      <th>zip</th>\n",
       "      <th>zips</th>\n",
       "      <th>zipup</th>\n",
       "      <th>zirconia</th>\n",
       "      <th>zithers</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zynga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30 rock</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Its always sunny</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mindy project</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks and rec</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scrubs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silicon valley</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Superstore</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The office</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veep</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 4511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aaahm  aah  abandoned  abbey  abdul  abg  ability  able  \\\n",
       "30 rock               0    0          0      0      0    0        0     0   \n",
       "B99                   0    0          0      0      0    0        0     0   \n",
       "Its always sunny      0    0          0      0      0    0        0     0   \n",
       "Mindy project         0    1          0      1      0    0        0     0   \n",
       "Parks and rec         0    0          2      0      1    0        1     3   \n",
       "Scrubs                0    0          0      0      0    1        0     2   \n",
       "Silicon valley        0    0          0      0      0    0        0     1   \n",
       "Superstore            0    0          0      0      0    0        0     0   \n",
       "The office            0    0          0      0      0    0        0     0   \n",
       "Veep                  1    0          0      0      0    0        0     0   \n",
       "\n",
       "                  abortion  abortions  ...  zero  zeroes  zip  zips  zipup  \\\n",
       "30 rock                  0          0  ...     0       0    0     0      0   \n",
       "B99                      0          0  ...     0       0    0     0      1   \n",
       "Its always sunny         0          0  ...     0       0    0     0      0   \n",
       "Mindy project            0          0  ...     0       0    0     0      0   \n",
       "Parks and rec            1          1  ...     1       0    0     0      0   \n",
       "Scrubs                   0          0  ...     0       0    0     0      0   \n",
       "Silicon valley           0          0  ...     0       2    1     0      0   \n",
       "Superstore               0          0  ...     0       0    0     0      0   \n",
       "The office               0          0  ...     0       0    0     1      0   \n",
       "Veep                     0          0  ...     0       0    0     0      0   \n",
       "\n",
       "                  zirconia  zithers  zone  zoned  zynga  \n",
       "30 rock                  0        0     0      0      0  \n",
       "B99                      0        0     0      0      0  \n",
       "Its always sunny         0        0     0      0      0  \n",
       "Mindy project            0        0     0      0      0  \n",
       "Parks and rec            0        0     1      1      0  \n",
       "Scrubs                   0        0     0      0      0  \n",
       "Silicon valley           0        1     0      0      1  \n",
       "Superstore               1        0     0      0      0  \n",
       "The office               0        0     0      0      0  \n",
       "Veep                     0        0     0      0      0  \n",
       "\n",
       "[10 rows x 4511 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in our document-term matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('pickle/dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "\n",
    "#import logging\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30 rock</th>\n",
       "      <th>B99</th>\n",
       "      <th>Its always sunny</th>\n",
       "      <th>Mindy project</th>\n",
       "      <th>Parks and rec</th>\n",
       "      <th>Scrubs</th>\n",
       "      <th>Silicon valley</th>\n",
       "      <th>Superstore</th>\n",
       "      <th>The office</th>\n",
       "      <th>Veep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaahm</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbey</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdul</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           30 rock  B99  Its always sunny  Mindy project  Parks and rec  \\\n",
       "aaahm            0    0                 0              0              0   \n",
       "aah              0    0                 0              1              0   \n",
       "abandoned        0    0                 0              0              2   \n",
       "abbey            0    0                 0              1              0   \n",
       "abdul            0    0                 0              0              1   \n",
       "\n",
       "           Scrubs  Silicon valley  Superstore  The office  Veep  \n",
       "aaahm           0               0           0           0     1  \n",
       "aah             0               0           0           0     0  \n",
       "abandoned       0               0           0           0     0  \n",
       "abbey           0               0           0           0     0  \n",
       "abdul           0               0           0           0     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"pickle/cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term), we need to specify two other parameters - the number of topics and the number of passes. Let's start the number of topics at 2, see if the results make sense, and increase the number from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"ill\" + 0.003*\"didnt\" + 0.003*\"kind\" + 0.003*\"said\" + 0.003*\"theres\" + 0.003*\"actually\" + 0.002*\"theyre\" + 0.002*\"whats\" + 0.002*\"doesnt\" + 0.002*\"doing\"'),\n",
       " (1,\n",
       "  '0.003*\"ill\" + 0.003*\"doing\" + 0.003*\"sure\" + 0.003*\"way\" + 0.003*\"shes\" + 0.003*\"talk\" + 0.003*\"years\" + 0.003*\"whats\" + 0.003*\"god\" + 0.002*\"actually\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"shes\" + 0.003*\"ill\" + 0.003*\"whats\" + 0.003*\"fine\" + 0.003*\"doing\" + 0.003*\"theres\" + 0.003*\"actually\" + 0.003*\"pretty\" + 0.003*\"better\" + 0.002*\"god\"'),\n",
       " (1,\n",
       "  '0.003*\"cause\" + 0.003*\"whats\" + 0.003*\"sure\" + 0.003*\"said\" + 0.003*\"theres\" + 0.003*\"years\" + 0.003*\"gotta\" + 0.003*\"crazy\" + 0.003*\"girl\" + 0.003*\"didnt\"'),\n",
       " (2,\n",
       "  '0.003*\"ill\" + 0.003*\"way\" + 0.003*\"talk\" + 0.003*\"sure\" + 0.003*\"doing\" + 0.003*\"vp\" + 0.003*\"didnt\" + 0.003*\"shit\" + 0.003*\"minutes\" + 0.002*\"said\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Load the dictionary containing character names for each show\\nimport pickle\\nwith open('pickle/char_dict.pickle', 'rb') as handle:\\n    char_dict = pickle.load(handle)\\n    print((char_dict))\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Load the dictionary containing character names for each show\n",
    "import pickle\n",
    "with open('pickle/char_dict.pickle', 'rb') as handle:\n",
    "    char_dict = pickle.load(handle)\n",
    "    print((char_dict))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Add the names of characters in the dictionary to stop words\\n#generate a flat list containing names from all shows\\nmore_stop_words = [item for sublist in char_dict.values() for item in sublist]\\n#After the first word cloud, character names feature prominently, so we'll add them to the stop words\\nmore_stop_words.append('Terry')\\nmore_stop_words.append('Captain')\\nmore_stop_words.append('Detective')\\nmore_stop_words.append('Sweet')\\nmore_stop_words.append('Ann')\\nmore_stop_words.append('Toofer')\\nmore_stop_words.append('PETER')\\nmore_stop_words.append('BIG HEAD')\\nmore_stop_words.append('Erlich')\\nmore_stop_words.append('COX')\\nmore_stop_words.append('JD')\\nmore_stop_words.append('Dr Cox')\\nmore_stop_words.append('Dr')\\nmore_stop_words.append('Jonah')\\nmore_stop_words.append('Amy')\\nmore_stop_words.append('Jan')\\nmore_stop_words.append('Senator')\\nmore_stop_words\\n\\nfrom sklearn.feature_extraction import text \\n# Add new stop words\\nstop_words = text.ENGLISH_STOP_WORDS.union(more_stop_words)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Add the names of characters in the dictionary to stop words\n",
    "#generate a flat list containing names from all shows\n",
    "more_stop_words = [item for sublist in char_dict.values() for item in sublist]\n",
    "#After the first word cloud, character names feature prominently, so we'll add them to the stop words\n",
    "more_stop_words.append('Terry')\n",
    "more_stop_words.append('Captain')\n",
    "more_stop_words.append('Detective')\n",
    "more_stop_words.append('Sweet')\n",
    "more_stop_words.append('Ann')\n",
    "more_stop_words.append('Toofer')\n",
    "more_stop_words.append('PETER')\n",
    "more_stop_words.append('BIG HEAD')\n",
    "more_stop_words.append('Erlich')\n",
    "more_stop_words.append('COX')\n",
    "more_stop_words.append('JD')\n",
    "more_stop_words.append('Dr Cox')\n",
    "more_stop_words.append('Dr')\n",
    "more_stop_words.append('Jonah')\n",
    "more_stop_words.append('Amy')\n",
    "more_stop_words.append('Jan')\n",
    "more_stop_words.append('Senator')\n",
    "more_stop_words\n",
    "\n",
    "from sklearn.feature_extraction import text \n",
    "# Add new stop words\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(more_stop_words)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Let\\'s update our document-term matrix with the new list of stop words\\nfrom sklearn.feature_extraction import text \\nfrom sklearn.feature_extraction.text import CountVectorizer\\n\\n# Read in cleaned data\\ndata_clean = pd.read_pickle(\\'data_df.pkl\\')\\n\\n# Recreate document-term matrix\\ncv = CountVectorizer(stop_words=stop_words)\\ndata_cv = cv.fit_transform(data_clean.Script)\\ndata_stop = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names_out())\\ndata_stop.index = data_clean.index\\n\\n# Pickle it for later use\\nimport pickle\\npickle.dump(cv, open(\"pickle/cv_stop.pkl\", \"wb\"))\\ndata_stop.to_pickle(\"pickle/dtm_stop.pkl\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Recreating document-term matrix after removing stop words of character names'''\n",
    "\n",
    "'''# Let's update our document-term matrix with the new list of stop words\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Read in cleaned data\n",
    "data_clean = pd.read_pickle('data_df.pkl')\n",
    "\n",
    "# Recreate document-term matrix\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "data_cv = cv.fit_transform(data_clean.Script)\n",
    "data_stop = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names_out())\n",
    "data_stop.index = data_clean.index\n",
    "\n",
    "# Pickle it for later use\n",
    "import pickle\n",
    "pickle.dump(cv, open(\"pickle/cv_stop.pkl\", \"wb\"))\n",
    "data_stop.to_pickle(\"pickle/dtm_stop.pkl\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"pickle/cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"doing\" + 0.004*\"best\" + 0.004*\"tie\" + 0.003*\"fine\" + 0.003*\"movie\" + 0.003*\"old\" + 0.003*\"wanna\" + 0.003*\"robot\" + 0.002*\"whats\" + 0.002*\"actually\"'),\n",
       " (1,\n",
       "  '0.003*\"years\" + 0.003*\"office\" + 0.003*\"things\" + 0.003*\"way\" + 0.003*\"ill\" + 0.003*\"vice\" + 0.003*\"sure\" + 0.003*\"shit\" + 0.003*\"vp\" + 0.003*\"used\"'),\n",
       " (2,\n",
       "  '0.004*\"ill\" + 0.003*\"god\" + 0.003*\"sure\" + 0.003*\"whats\" + 0.003*\"theres\" + 0.003*\"didnt\" + 0.003*\"hell\" + 0.003*\"actually\" + 0.003*\"doing\" + 0.003*\"talk\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"doing\" + 0.004*\"best\" + 0.004*\"tie\" + 0.004*\"fine\" + 0.004*\"old\" + 0.004*\"movie\" + 0.003*\"wanna\" + 0.003*\"robot\" + 0.003*\"didnt\" + 0.003*\"actually\"'),\n",
       " (1,\n",
       "  '0.004*\"ill\" + 0.003*\"actually\" + 0.003*\"doing\" + 0.003*\"didnt\" + 0.003*\"said\" + 0.003*\"whats\" + 0.003*\"sure\" + 0.003*\"theres\" + 0.003*\"kind\" + 0.003*\"talk\"'),\n",
       " (2,\n",
       "  '0.004*\"god\" + 0.004*\"shes\" + 0.003*\"things\" + 0.003*\"department\" + 0.003*\"public\" + 0.003*\"parks\" + 0.003*\"fell\" + 0.003*\"politics\" + 0.003*\"whats\" + 0.003*\"way\"'),\n",
       " (3,\n",
       "  '0.004*\"shit\" + 0.004*\"vp\" + 0.004*\"vice\" + 0.004*\"cutlery\" + 0.003*\"maam\" + 0.003*\"office\" + 0.003*\"plastic\" + 0.003*\"plastics\" + 0.003*\"things\" + 0.003*\"used\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These topics aren't looking too great. We've tried modifying our parameters. Let's try modifying our terms list as well.\n",
    "\n",
    "## Topic Modeling - Attempt #2 (Nouns Only)\n",
    "One popular trick is to look only at terms that are from one part of speech (only nouns, only adjectives, etc.). Check out the UPenn tag set: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Script</th>\n",
       "      <th>Show_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30 rock</th>\n",
       "      <td>mom  i nursed zach til he was  months lisa exc...</td>\n",
       "      <td>30 Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B99</th>\n",
       "      <td>jake this job is eating me alive i cant breat...</td>\n",
       "      <td>Brooklyn Nine Nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Its always sunny</th>\n",
       "      <td>dennis another big night fellas one hundred ei...</td>\n",
       "      <td>Its Always Sunny in Philadelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mindy project</th>\n",
       "      <td>mindy you have an idea of how your life is goi...</td>\n",
       "      <td>The Mindy Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks and rec</th>\n",
       "      <td>leslie   i love politics ive always loved  pol...</td>\n",
       "      <td>Parks and Recreation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scrubs</th>\n",
       "      <td>jd  since i was eleven years old ive been able...</td>\n",
       "      <td>Scrubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silicon valley</th>\n",
       "      <td>big head hey man some guys from zynga are  thr...</td>\n",
       "      <td>Silicon valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Superstore</th>\n",
       "      <td>narrator the american superstore onestop shopp...</td>\n",
       "      <td>Superstore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The office</th>\n",
       "      <td>michael all right jim your quarterlies look ve...</td>\n",
       "      <td>The Office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veep</th>\n",
       "      <td>gary  thats a fork madam vice president  selin...</td>\n",
       "      <td>Veep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Script  \\\n",
       "30 rock           mom  i nursed zach til he was  months lisa exc...   \n",
       "B99                jake this job is eating me alive i cant breat...   \n",
       "Its always sunny  dennis another big night fellas one hundred ei...   \n",
       "Mindy project     mindy you have an idea of how your life is goi...   \n",
       "Parks and rec     leslie   i love politics ive always loved  pol...   \n",
       "Scrubs            jd  since i was eleven years old ive been able...   \n",
       "Silicon valley    big head hey man some guys from zynga are  thr...   \n",
       "Superstore        narrator the american superstore onestop shopp...   \n",
       "The office        michael all right jim your quarterlies look ve...   \n",
       "Veep              gary  thats a fork madam vice president  selin...   \n",
       "\n",
       "                                         Show_name  \n",
       "30 rock                                    30 Rock  \n",
       "B99                             Brooklyn Nine Nine  \n",
       "Its always sunny  Its Always Sunny in Philadelphia  \n",
       "Mindy project                    The Mindy Project  \n",
       "Parks and rec                 Parks and Recreation  \n",
       "Scrubs                                      Scrubs  \n",
       "Silicon valley                      Silicon valley  \n",
       "Superstore                              Superstore  \n",
       "The office                              The Office  \n",
       "Veep                                          Veep  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data, before the CountVectorizer step\n",
    "data_clean = pd.read_pickle('pickle/data_clean.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30 rock</th>\n",
       "      <td>mom i zach til months werent confusion lisa br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B99</th>\n",
       "      <td>jake job i breathe years guy man hat im jake i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Its always sunny</th>\n",
       "      <td>dennis night fellas dollars cents christ charl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mindy project</th>\n",
       "      <td>mindy idea life i kid i watch comedies living ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks and rec</th>\n",
       "      <td>leslie i politics politics game leslie people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scrubs</th>\n",
       "      <td>jd i years anything storms girlfriend yelling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silicon valley</th>\n",
       "      <td>head hey man guys zynga perplexus tourney stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Superstore</th>\n",
       "      <td>narrator superstore shopping everything fatter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The office</th>\n",
       "      <td>michael jim quarterlies things jim oh i come m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veep</th>\n",
       "      <td>thats fork vice president thanks debrief anna ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Script\n",
       "30 rock           mom i zach til months werent confusion lisa br...\n",
       "B99               jake job i breathe years guy man hat im jake i...\n",
       "Its always sunny  dennis night fellas dollars cents christ charl...\n",
       "Mindy project     mindy idea life i kid i watch comedies living ...\n",
       "Parks and rec     leslie i politics politics game leslie people ...\n",
       "Scrubs            jd i years anything storms girlfriend yelling ...\n",
       "Silicon valley    head hey man guys zynga perplexus tourney stan...\n",
       "Superstore        narrator superstore shopping everything fatter...\n",
       "The office        michael jim quarterlies things jim oh i come m...\n",
       "Veep              thats fork vice president thanks debrief anna ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns = pd.DataFrame(data_clean.Script.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT THE PREVIOUSLY DETERMINED LIST OF STOP WORDS FOR USE FROM ANOTHER NOTEBOOK\n",
    "import pickle\n",
    "stop_words_list = pickle.load(open(\"pickle/stop_list.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aah</th>\n",
       "      <th>abdul</th>\n",
       "      <th>abg</th>\n",
       "      <th>ability</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abortions</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absurdity</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>zarp</th>\n",
       "      <th>zeep</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroes</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipup</th>\n",
       "      <th>zirconia</th>\n",
       "      <th>zithers</th>\n",
       "      <th>zone</th>\n",
       "      <th>zynga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30 rock</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Its always sunny</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mindy project</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks and rec</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scrubs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silicon valley</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Superstore</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The office</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veep</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aah  abdul  abg  ability  abortion  abortions  abraham  \\\n",
       "30 rock             0      0    0        0         0          0        0   \n",
       "B99                 0      0    0        0         0          0        0   \n",
       "Its always sunny    0      0    0        0         0          0        0   \n",
       "Mindy project       1      0    0        0         0          0        0   \n",
       "Parks and rec       0      1    0        1         1          1        0   \n",
       "Scrubs              0      0    1        0         0          0        0   \n",
       "Silicon valley      0      0    0        0         0          0        0   \n",
       "Superstore          0      0    0        0         0          0        0   \n",
       "The office          0      0    0        0         0          0        1   \n",
       "Veep                0      0    0        0         0          0        0   \n",
       "\n",
       "                  absolute  absurdity  access  ...  zarp  zeep  zero  zeroes  \\\n",
       "30 rock                  0          0       0  ...     0     0     0       0   \n",
       "B99                      0          0       1  ...     1     1     0       0   \n",
       "Its always sunny         1          0       0  ...     0     0     0       0   \n",
       "Mindy project            0          0       2  ...     0     0     0       0   \n",
       "Parks and rec            0          0       0  ...     0     0     1       0   \n",
       "Scrubs                   0          0       0  ...     0     0     0       0   \n",
       "Silicon valley           0          0       0  ...     0     0     0       2   \n",
       "Superstore               0          0       0  ...     0     0     0       0   \n",
       "The office               0          0       0  ...     0     0     0       0   \n",
       "Veep                     0          1       2  ...     0     0     0       0   \n",
       "\n",
       "                  zip  zipup  zirconia  zithers  zone  zynga  \n",
       "30 rock             0      0         0        0     0      0  \n",
       "B99                 0      1         0        0     0      0  \n",
       "Its always sunny    0      0         0        0     0      0  \n",
       "Mindy project       0      0         0        0     0      0  \n",
       "Parks and rec       0      0         0        0     1      0  \n",
       "Scrubs              0      0         0        0     0      0  \n",
       "Silicon valley      1      0         0        1     0      1  \n",
       "Superstore          0      0         1        0     0      0  \n",
       "The office          0      0         0        0     0      0  \n",
       "Veep                0      0         0        0     0      0  \n",
       "\n",
       "[10 rows x 2575 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(stop_words_list)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.Script)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names_out())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"office\" + 0.004*\"years\" + 0.004*\"things\" + 0.004*\"vice\" + 0.004*\"way\" + 0.004*\"shes\" + 0.004*\"meeting\" + 0.003*\"vp\" + 0.003*\"kind\" + 0.003*\"plastics\"'),\n",
       " (1,\n",
       "  '0.005*\"way\" + 0.005*\"years\" + 0.005*\"gon\" + 0.005*\"kind\" + 0.004*\"things\" + 0.004*\"day\" + 0.004*\"hell\" + 0.004*\"ill\" + 0.004*\"money\" + 0.004*\"shes\"')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"years\" + 0.005*\"things\" + 0.005*\"way\" + 0.005*\"office\" + 0.005*\"vice\" + 0.004*\"gon\" + 0.004*\"kind\" + 0.004*\"meeting\" + 0.004*\"coffee\" + 0.004*\"vp\"'),\n",
       " (1,\n",
       "  '0.005*\"code\" + 0.004*\"way\" + 0.004*\"money\" + 0.004*\"ill\" + 0.004*\"day\" + 0.004*\"idea\" + 0.004*\"gon\" + 0.004*\"room\" + 0.004*\"kind\" + 0.004*\"minutes\"'),\n",
       " (2,\n",
       "  '0.006*\"things\" + 0.006*\"shes\" + 0.005*\"years\" + 0.004*\"way\" + 0.004*\"life\" + 0.004*\"problem\" + 0.004*\"department\" + 0.004*\"boyfriend\" + 0.004*\"kind\" + 0.004*\"stuff\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try topics = 3\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"dollars\" + 0.006*\"kind\" + 0.006*\"idea\" + 0.006*\"money\" + 0.006*\"world\" + 0.004*\"things\" + 0.004*\"way\" + 0.004*\"gon\" + 0.004*\"minutes\" + 0.004*\"code\"'),\n",
       " (1,\n",
       "  '0.006*\"years\" + 0.005*\"things\" + 0.005*\"gon\" + 0.005*\"shes\" + 0.005*\"kind\" + 0.004*\"way\" + 0.004*\"office\" + 0.004*\"ill\" + 0.004*\"vice\" + 0.004*\"life\"'),\n",
       " (2,\n",
       "  '0.007*\"hell\" + 0.006*\"god\" + 0.006*\"way\" + 0.006*\"room\" + 0.005*\"tool\" + 0.005*\"girl\" + 0.004*\"doctor\" + 0.004*\"care\" + 0.004*\"ill\" + 0.004*\"gon\"'),\n",
       " (3,\n",
       "  '0.007*\"things\" + 0.007*\"department\" + 0.006*\"shes\" + 0.006*\"politics\" + 0.005*\"way\" + 0.004*\"years\" + 0.004*\"problem\" + 0.004*\"boyfriend\" + 0.004*\"power\" + 0.004*\"mayor\"')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"way\" + 0.000*\"kind\" + 0.000*\"ill\" + 0.000*\"god\" + 0.000*\"minutes\" + 0.000*\"shes\" + 0.000*\"years\" + 0.000*\"things\" + 0.000*\"room\" + 0.000*\"office\"'),\n",
       " (1,\n",
       "  '0.006*\"way\" + 0.006*\"things\" + 0.006*\"years\" + 0.006*\"money\" + 0.005*\"dollars\" + 0.005*\"kind\" + 0.004*\"world\" + 0.004*\"shes\" + 0.004*\"idea\" + 0.004*\"problem\"'),\n",
       " (2,\n",
       "  '0.007*\"manager\" + 0.007*\"branch\" + 0.006*\"kind\" + 0.004*\"gon\" + 0.004*\"years\" + 0.004*\"phone\" + 0.004*\"problem\" + 0.004*\"question\" + 0.004*\"office\" + 0.004*\"company\"'),\n",
       " (3,\n",
       "  '0.005*\"vice\" + 0.005*\"office\" + 0.005*\"way\" + 0.005*\"things\" + 0.005*\"shes\" + 0.005*\"whats\" + 0.005*\"vp\" + 0.004*\"years\" + 0.004*\"movie\" + 0.004*\"plastics\"'),\n",
       " (4,\n",
       "  '0.006*\"life\" + 0.006*\"day\" + 0.006*\"gon\" + 0.006*\"ill\" + 0.005*\"doctor\" + 0.005*\"years\" + 0.005*\"room\" + 0.005*\"girl\" + 0.005*\"kind\" + 0.004*\"way\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 5 topics; 30 passes\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=5, id2word=id2wordn, passes=30)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #3 (Nouns and Adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30 rock</th>\n",
       "      <td>mom i zach til months lisa werent nipple confu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B99</th>\n",
       "      <td>jake job alive i breathe i years good guy man ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Its always sunny</th>\n",
       "      <td>dennis big night fellas dollars sixtyseven cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mindy project</th>\n",
       "      <td>mindy idea life i kid i watch romantic comedie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks and rec</th>\n",
       "      <td>leslie i politics ive politics game leslie peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scrubs</th>\n",
       "      <td>jd i eleven years old ive able anything storms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silicon valley</th>\n",
       "      <td>big head hey man guys zynga allnight perplexus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Superstore</th>\n",
       "      <td>narrator american superstore onestop shopping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The office</th>\n",
       "      <td>michael right jim quarterlies good things libr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veep</th>\n",
       "      <td>gary thats fork madam vice president thanks de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Script\n",
       "30 rock           mom i zach til months lisa werent nipple confu...\n",
       "B99               jake job alive i breathe i years good guy man ...\n",
       "Its always sunny  dennis big night fellas dollars sixtyseven cen...\n",
       "Mindy project     mindy idea life i kid i watch romantic comedie...\n",
       "Parks and rec     leslie i politics ive politics game leslie peo...\n",
       "Scrubs            jd i eleven years old ive able anything storms...\n",
       "Silicon valley    big head hey man guys zynga allnight perplexus...\n",
       "Superstore        narrator american superstore onestop shopping ...\n",
       "The office        michael right jim quarterlies good things libr...\n",
       "Veep              gary thats fork madam vice president thanks de..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns_adj = pd.DataFrame(data_clean.Script.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aah</th>\n",
       "      <th>abdul</th>\n",
       "      <th>abg</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abortions</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absurdity</th>\n",
       "      <th>...</th>\n",
       "      <th>zarp</th>\n",
       "      <th>zeep</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroes</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipup</th>\n",
       "      <th>zirconia</th>\n",
       "      <th>zithers</th>\n",
       "      <th>zone</th>\n",
       "      <th>zynga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30 rock</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Its always sunny</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mindy project</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks and rec</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scrubs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silicon valley</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Superstore</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The office</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veep</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 3324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aah  abdul  abg  ability  able  abortion  abortions  \\\n",
       "30 rock             0      0    0        0     0         0          0   \n",
       "B99                 0      0    0        0     0         0          0   \n",
       "Its always sunny    0      0    0        0     0         0          0   \n",
       "Mindy project       1      0    0        0     0         0          0   \n",
       "Parks and rec       0      1    0        1     3         1          1   \n",
       "Scrubs              0      0    1        0     2         0          0   \n",
       "Silicon valley      0      0    0        0     1         0          0   \n",
       "Superstore          0      0    0        0     0         0          0   \n",
       "The office          0      0    0        0     0         0          0   \n",
       "Veep                0      0    0        0     0         0          0   \n",
       "\n",
       "                  abraham  absolute  absurdity  ...  zarp  zeep  zero  zeroes  \\\n",
       "30 rock                 0         0          0  ...     0     0     0       0   \n",
       "B99                     0         0          0  ...     1     1     0       0   \n",
       "Its always sunny        0         1          0  ...     0     0     0       0   \n",
       "Mindy project           0         0          0  ...     0     0     0       0   \n",
       "Parks and rec           0         1          0  ...     0     0     1       0   \n",
       "Scrubs                  0         0          0  ...     0     0     0       0   \n",
       "Silicon valley          0         0          0  ...     0     0     0       2   \n",
       "Superstore              0         0          0  ...     0     0     0       0   \n",
       "The office              1         0          0  ...     0     0     0       0   \n",
       "Veep                    0         0          1  ...     0     0     0       0   \n",
       "\n",
       "                  zip  zipup  zirconia  zithers  zone  zynga  \n",
       "30 rock             0      0         0        0     0      0  \n",
       "B99                 0      1         0        0     0      0  \n",
       "Its always sunny    0      0         0        0     0      0  \n",
       "Mindy project       0      0         0        0     0      0  \n",
       "Parks and rec       0      0         0        0     1      0  \n",
       "Scrubs              0      0         0        0     0      0  \n",
       "Silicon valley      1      0         0        1     0      1  \n",
       "Superstore          0      0         1        0     0      0  \n",
       "The office          0      0         0        0     0      0  \n",
       "Veep                0      0         0        0     0      0  \n",
       "\n",
       "[10 rows x 3324 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.Script)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names_out())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"god\" + 0.003*\"dollars\" + 0.003*\"gon\" + 0.003*\"day\" + 0.003*\"money\" + 0.003*\"hell\" + 0.003*\"problem\" + 0.003*\"second\" + 0.003*\"hard\" + 0.003*\"better\"'),\n",
       " (1,\n",
       "  '0.003*\"gon\" + 0.003*\"office\" + 0.003*\"old\" + 0.003*\"vice\" + 0.003*\"vp\" + 0.003*\"sex\" + 0.003*\"movie\" + 0.002*\"life\" + 0.002*\"hi\" + 0.002*\"dog\"')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"gon\" + 0.004*\"god\" + 0.004*\"problem\" + 0.003*\"money\" + 0.003*\"world\" + 0.003*\"life\" + 0.003*\"dollars\" + 0.003*\"music\" + 0.003*\"cause\" + 0.003*\"office\"'),\n",
       " (1,\n",
       "  '0.004*\"shit\" + 0.004*\"vp\" + 0.004*\"old\" + 0.004*\"vice\" + 0.003*\"office\" + 0.003*\"cutlery\" + 0.003*\"plastics\" + 0.003*\"plastic\" + 0.003*\"dog\" + 0.003*\"movie\"'),\n",
       " (2,\n",
       "  '0.005*\"day\" + 0.004*\"gon\" + 0.004*\"hard\" + 0.003*\"tool\" + 0.003*\"family\" + 0.003*\"girl\" + 0.003*\"janitor\" + 0.003*\"interns\" + 0.003*\"second\" + 0.003*\"doctor\"')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 3 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"money\" + 0.004*\"idea\" + 0.004*\"music\" + 0.004*\"gon\" + 0.004*\"life\" + 0.004*\"old\" + 0.003*\"dollars\" + 0.003*\"world\" + 0.003*\"college\" + 0.003*\"hello\"'),\n",
       " (1,\n",
       "  '0.005*\"god\" + 0.005*\"day\" + 0.004*\"hard\" + 0.004*\"department\" + 0.003*\"public\" + 0.003*\"problem\" + 0.003*\"boyfriend\" + 0.003*\"gon\" + 0.003*\"hell\" + 0.003*\"doesnt\"'),\n",
       " (2,\n",
       "  '0.005*\"manager\" + 0.005*\"branch\" + 0.005*\"corporate\" + 0.005*\"regional\" + 0.003*\"office\" + 0.003*\"problem\" + 0.003*\"important\" + 0.003*\"gon\" + 0.003*\"phone\" + 0.003*\"company\"'),\n",
       " (3,\n",
       "  '0.005*\"vice\" + 0.004*\"vp\" + 0.004*\"shit\" + 0.004*\"office\" + 0.004*\"crazy\" + 0.004*\"coffee\" + 0.004*\"cutlery\" + 0.004*\"dog\" + 0.003*\"plastic\" + 0.003*\"isnt\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"heat\" + 0.005*\"gon\" + 0.004*\"cause\" + 0.004*\"coffee\" + 0.004*\"deer\" + 0.004*\"crazy\" + 0.004*\"baby\" + 0.004*\"tour\" + 0.004*\"friday\" + 0.004*\"bagels\"'),\n",
       " (1,\n",
       "  '0.005*\"gon\" + 0.005*\"god\" + 0.005*\"day\" + 0.004*\"hell\" + 0.004*\"girl\" + 0.004*\"second\" + 0.004*\"hard\" + 0.003*\"todd\" + 0.003*\"care\" + 0.003*\"doctor\"'),\n",
       " (2,\n",
       "  '0.005*\"money\" + 0.005*\"music\" + 0.005*\"idea\" + 0.004*\"gon\" + 0.004*\"old\" + 0.004*\"life\" + 0.004*\"hello\" + 0.004*\"dollars\" + 0.004*\"college\" + 0.004*\"world\"'),\n",
       " (3,\n",
       "  '0.007*\"vp\" + 0.007*\"vice\" + 0.006*\"cutlery\" + 0.006*\"plastic\" + 0.006*\"office\" + 0.006*\"plastics\" + 0.005*\"shit\" + 0.005*\"dog\" + 0.005*\"meeting\" + 0.004*\"maam\"'),\n",
       " (4,\n",
       "  '0.006*\"god\" + 0.006*\"public\" + 0.006*\"department\" + 0.005*\"politics\" + 0.004*\"parks\" + 0.004*\"boyfriend\" + 0.004*\"problem\" + 0.004*\"mayor\" + 0.004*\"power\" + 0.003*\"news\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 5 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=5, id2word=id2wordna, passes=20)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Topics in Each Document\n",
    "Out of the topic models we looked at, the nouns and adjectives, 4 topic one made the most sense. So let's pull that down here and run it through some more iterations to get more fine-tuned topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"god\" + 0.000*\"gon\" + 0.000*\"money\" + 0.000*\"hell\" + 0.000*\"day\" + 0.000*\"music\" + 0.000*\"whoa\" + 0.000*\"hi\" + 0.000*\"doesnt\" + 0.000*\"everybody\"'),\n",
       " (1,\n",
       "  '0.005*\"office\" + 0.005*\"vice\" + 0.004*\"vp\" + 0.004*\"gon\" + 0.004*\"life\" + 0.004*\"dog\" + 0.004*\"cutlery\" + 0.003*\"hi\" + 0.003*\"plastic\" + 0.003*\"sex\"'),\n",
       " (2,\n",
       "  '0.007*\"movie\" + 0.007*\"old\" + 0.007*\"tie\" + 0.006*\"robot\" + 0.005*\"team\" + 0.004*\"store\" + 0.004*\"terrible\" + 0.004*\"ham\" + 0.003*\"whoa\" + 0.003*\"hello\"'),\n",
       " (3,\n",
       "  '0.006*\"dollars\" + 0.006*\"money\" + 0.005*\"idea\" + 0.004*\"world\" + 0.004*\"gon\" + 0.004*\"hell\" + 0.003*\"music\" + 0.003*\"college\" + 0.003*\"god\" + 0.003*\"youve\"'),\n",
       " (4,\n",
       "  '0.007*\"god\" + 0.006*\"public\" + 0.006*\"department\" + 0.005*\"politics\" + 0.005*\"parks\" + 0.004*\"problem\" + 0.004*\"boyfriend\" + 0.004*\"mayor\" + 0.004*\"power\" + 0.003*\"matter\"'),\n",
       " (5,\n",
       "  '0.006*\"day\" + 0.005*\"hard\" + 0.005*\"gon\" + 0.005*\"tool\" + 0.003*\"doctor\" + 0.003*\"girl\" + 0.003*\"hell\" + 0.003*\"second\" + 0.003*\"family\" + 0.003*\"god\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=6, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '30 rock'),\n",
       " (2, 'B99'),\n",
       " (3, 'Its always sunny'),\n",
       " (1, 'Mindy project'),\n",
       " (4, 'Parks and rec'),\n",
       " (5, 'Scrubs'),\n",
       " (3, 'Silicon valley'),\n",
       " (5, 'Superstore'),\n",
       " (3, 'The office'),\n",
       " (1, 'Veep')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each transcript contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
